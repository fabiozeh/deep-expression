{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gs2Yk5y3IxKb"
   },
   "source": [
    "Deep artificial neural network for expressive timing and dynamics predictions in musical pieces\n",
    "---------------\n",
    "\n",
    "This notebook loads a sequential dataset with score and performance information and uses it to train and test a deep artificial neural network for generating onset timing deviation and peak loudness level of notes from musical pieces.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing to install XLA (for training on TPUs) and pytorch-lightning (skip if not using Google Colab):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "\n",
    "!python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install pytorch_lightning --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters to set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "runLocal = True  # set to False for using Google Colab\n",
    "\n",
    "class Args:\n",
    "    pass\n",
    "        \n",
    "args = Args()\n",
    "args.data = 'MNv_I_train_sequences_fold_0.data'\n",
    "args.val_data = 'MNv_I_val_sequences_fold_0.data'\n",
    "args.model_state = '2021-05-19-test.pth'\n",
    "args.eval = False\n",
    "args.gen_attr = ['ioiRatio', 'durationSecs', 'peakLevel']\n",
    "args.vocab_size = 92\n",
    "args.lr = 3e-4\n",
    "args.seq_len = 60\n",
    "args.hidden_size = 64\n",
    "args.dec_layers = 2\n",
    "args.enc_layers = 2\n",
    "args.dropout = 0.04\n",
    "args.batch_size = 128\n",
    "args.epochs = 3\n",
    "args.max_steps = 1000\n",
    "args.scheduler_step = 15000\n",
    "args.lr_decay_by = 0.6\n",
    "args.stride = 50\n",
    "args.context = 5\n",
    "args.no_ctx_train = False\n",
    "args.dev_run = False\n",
    "args.workers = 0\n",
    "args.cpu_only = True\n",
    "args.pitch_dict = 'mF_pitch_dict.data'\n",
    "args.norm = 'MNv_I_normalizer_fold_0.data'\n",
    "args.test_data = 'MNv_I_test_sequences_fold_0.data'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting path and loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "\n",
    "if runLocal:\n",
    "    pathRoot = 'data/'\n",
    "else:\n",
    "    pathRoot = '/content/drive/My Drive/colab_data/'\n",
    "    !wget \"https://raw.githubusercontent.com/fabiozeh/deep-expression/master/dataloader.py\"\n",
    "    !wget \"https://raw.githubusercontent.com/fabiozeh/deep-expression/master/seq2seq.py\"\n",
    "\n",
    "    \n",
    "with open(os.path.join(pathRoot, args.data), 'rb') as seq_path:\n",
    "    train = pickle.load(seq_path)\n",
    "with open(os.path.join(pathRoot, args.val_data), 'rb') as seq_path:\n",
    "    val = pickle.load(seq_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DzL3Y9MOIxLG"
   },
   "source": [
    "#### Defining the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import seq2seq\n",
    "\n",
    "model = seq2seq.Net(train[0][0][0].shape[1],\n",
    "            len(args.gen_attr),\n",
    "            vocab_size=args.vocab_size, # len(ix_to_lex) + 4,  # 0 = pad, len+1 = UKN, len+2 = END, len+3 = SOS\n",
    "            hidden_size=args.hidden_size,\n",
    "            dropout_rate=args.dropout,\n",
    "            lr=args.lr,\n",
    "            context=(0 if args.no_ctx_train else args.context),\n",
    "            window=(0 if args.no_ctx_train else args.stride),\n",
    "            scheduler_step=args.scheduler_step,\n",
    "            lr_decay_by=args.lr_decay_by,\n",
    "            dec_layers=args.dec_layers,\n",
    "            enc_layers=args.enc_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jB1zXiP9IxLV"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "colab_type": "code",
    "id": "JpghmUE3IxLX",
    "outputId": "6c2e7186-6bf7-41ac-ea28-387da0e9d393"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning sequence to sequence model training invoked with command:\n",
      "/usr/local/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/fabiojmortega/Library/Jupyter/runtime/kernel-8849db08-ba28-4885-8b95-3e33cf57a89f.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name    | Type    | Params\n",
      "------------------------------------\n",
      "0 | encoder | Encoder | 132 K \n",
      "1 | decoder | Decoder | 120 K \n",
      "------------------------------------\n",
      "253 K     Trainable params\n",
      "0         Non-trainable params\n",
      "253 K     Total params\n",
      "1.013     Total estimated model params size (MB)\n",
      "/usr/local/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "223422bc2ef44c16b15703b4b4bbfe87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c2a10e94794218b330a467fc44f178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set MSE for ioiRatio: 0.6290845473562796\n",
      "Validation set MSE for durationSecs: 0.9304977202042732\n",
      "Validation set MSE for peakLevel: 1.1442185567174958\n"
     ]
    }
   ],
   "source": [
    "seq2seq.run_with_args(model, train, val, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mv-wgSVTIxLj"
   },
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J2eV2YV0IxL1",
    "outputId": "2af81d2a-bd9b-47a8-a0d3-038baaf6e948"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Load model\n",
    "model.load_state_dict(torch.load(STATE_DICT_NAME))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "Yhat, mse = seq2seq.evaluation(val, args.seq_len, model, stride=args.stride, output_cols=args.gen_attr,\n",
    "                               context=args.context, pad_both_ends=(not args.no_ctx_train))\n",
    "    \n",
    "for i, col in enumerate(args.gen_attr):\n",
    "    print('Validation set MSE for ' + col + ': ' + str(np.mean(mse[:, i])))\n",
    "    print('Minimum MSE among pieces for ' + col + ': ' + str(mse[:, i].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "piece = 0\n",
    "attr = ['durationSecs']\n",
    "plt.figure(figsize=(21, 5))\n",
    "plt.plot(Yhat[piece][:200,1])\n",
    "plt.plot(test[piece][0][1].loc[:,attr].to_numpy()[:200])\n",
    "# print(test_sequences[piece][1].columns[attr])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of dynamics of different performances of same piece for context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "with open(os.path.join(pathRoot, 'single fold/LvB_train_sequences.data'), 'rb') as seq_path:\n",
    "    trainsf = pickle.load(seq_path)\n",
    "attr = 'ioiRatio'\n",
    "plt.figure(figsize=(21, 5))\n",
    "plt.plot(trainsf[35][0][1].loc[:,attr].to_numpy()[2500:])\n",
    "plt.plot(trainsf[70][0][1].loc[:,attr].to_numpy()[2500:])\n",
    "plt.figure(figsize=(21, 5))\n",
    "plt.plot(trainsf[42][0][1].loc[:,attr].to_numpy()[1000:1300])\n",
    "plt.plot(trainsf[77][0][1].loc[:,attr].to_numpy()[1000:1300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(pathRoot, 'single fold/LvB_train_sequences.data'), 'rb') as seq_path:\n",
    "    trainsf = pickle.load(seq_path)\n",
    "attr = 'ioiRatio'\n",
    "mse_human1 = np.mean((trainsf[70][0][1].loc[:, attr].iloc[:3120].to_numpy('float64') - trainsf[35][0][1].loc[:, attr].iloc[:3120].to_numpy('float64')) ** 2)\n",
    "mse_human2 = np.mean((trainsf[42][0][1].loc[:, attr].to_numpy('float64') - trainsf[77][0][1].loc[:, attr].to_numpy('float64')) ** 2)\n",
    "\n",
    "print(\"MSE between two performances of sonata 7, 2nd mvmt. (has alignment issues): \" + str(mse_human1))\n",
    "print(\"MSE between two performances of sonata 7, 3rd mvmt.: \" + str(mse_human2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listen to a piece synthesized with the generated expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import IPython.display\n",
    "import expression_modeling as m\n",
    "\n",
    "with open(pathRoot + args.pitch_dict, 'rb') as filehandle:\n",
    "    lex_to_ix = pickle.load(filehandle)\n",
    "    ix_to_lex = {v: k for k, v in lex_to_ix.items()}\n",
    "with open(pathRoot + args.norm, 'rb') as filehandle:\n",
    "    moments, cols = pickle.load(filehandle)\n",
    "    moments = dict(zip(cols, list(moments)))\n",
    "with open(os.path.join(pathRoot, args.test_data), 'rb') as seq_path:\n",
    "    test = pickle.load(seq_path)\n",
    "\n",
    "# piece to synthesize:\n",
    "pieceNum = 0\n",
    "pieceId = val[pieceNum][1]\n",
    "print(pieceId)\n",
    "\n",
    "pred = Yhat[pieceNum][:,:2]\n",
    "ref = val[pieceNum][0][1].ioiRatio\n",
    "no_dev = np.asarray([val[pieceNum][0][2][2,0]] * val[pieceNum][0][1].shape[0])\n",
    "dev_rand = np.random.normal(size=val[pieceNum][0][1].shape[0]) * val[pieceNum][0][2][2,1] + val[pieceNum][0][2][2,0]\n",
    "\n",
    "pm = m.midi_performance(val[pieceNum][0], pred, moments, ix_to_lex, method='ioiRatio')\n",
    "IPython.display.Audio(pm.fluidsynth(fs=44100), rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "PhraseDynamicsLSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
