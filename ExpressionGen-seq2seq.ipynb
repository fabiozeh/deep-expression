{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gs2Yk5y3IxKb"
   },
   "source": [
    "Deep artificial neural network for expressive timing and dynamics predictions in musical pieces\n",
    "---------------\n",
    "\n",
    "This notebook loads a sequential dataset with score and performance information and uses it to train and test a deep artificial neural network for generating onset timing deviation and peak loudness level of notes from musical pieces.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parameters to set:\n",
    "\n",
    "runLocal = True  # False for using Google Colab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and preprocess training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "5sQCWWMtIxKg",
    "outputId": "c0937385-1926-4992-ccd9-6dba03c3e71a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "#  read dataset\n",
    "\n",
    "if runLocal:\n",
    "    pathRoot = 'data/'\n",
    "else:\n",
    "    pathRoot = '/content/drive/My Drive/colab_data/'\n",
    "\n",
    "with open(os.path.join(pathRoot, 'LvB_train_sequences.data'), 'rb') as seq_path:\n",
    "    train = pickle.load(seq_path)\n",
    "with open(os.path.join(pathRoot, 'LvB_val_sequences.data'), 'rb') as seq_path:\n",
    "    val = pickle.load(seq_path)\n",
    "with open(pathRoot + 'LvB_pitch_dict.data', 'rb') as filehandle:\n",
    "    lex_to_ix = pickle.load(filehandle)\n",
    "    ix_to_lex = {v: k for k, v in lex_to_ix.items()}\n",
    "with open(pathRoot + 'LvB_normalizer.data', 'rb') as filehandle:\n",
    "    moments, cols = pickle.load(filehandle)\n",
    "    moments = dict(zip(cols, list(moments)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DzL3Y9MOIxLG"
   },
   "source": [
    "#### Define the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import dataloader as dl\n",
    "\n",
    "np.random.seed(1728)\n",
    "torch.manual_seed(1728)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, n_x, vocab_col, vocab_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.vocab_col = vocab_col\n",
    "        self.pitchEmbedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=hidden_size, padding_idx=0)\n",
    "        self.harmonyRhythmProjector = nn.Linear(in_features=n_x - 1, out_features=hidden_size)\n",
    "        self.rnn = nn.GRU(2 * hidden_size, 2 * hidden_size, num_layers=1, bidirectional=True)\n",
    "    \n",
    "    def forward(self, x, lengths):\n",
    "        pitch = torch.LongTensor(x[:, :, self.vocab_col])\n",
    "        harmRhythm = torch.cat([torch.FloatTensor(x[:,:,:self.vocab_col]), torch.FloatTensor(x[:,:,self.vocab_col+1:])], dim=2)\n",
    "        \n",
    "        pitch = self.pitchEmbedding(pitch)\n",
    "        harmRhythm = self.harmonyRhythmProjector(harmRhythm)\n",
    "        src_vec = torch.cat([pitch, harmRhythm], dim=2)\n",
    "        sequence = nn.utils.rnn.pack_padded_sequence(src_vec, lengths, enforce_sorted=False)\n",
    "        output, _ = self.rnn(sequence)\n",
    "        return nn.utils.rnn.pad_packed_sequence(output)\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        \n",
    "    def forward(self, ):\n",
    "    \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        \n",
    "    def forward(self, ):\n",
    "        \n",
    "\n",
    "class Net(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, seq_length, n_x, n_y, vocab_col, vocab_size, batch_size, \n",
    "                 hidden_size, dropout_rate, output_cols, lr):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.seq_length = seq_length\n",
    "        self.batch_size = batch_size\n",
    "        self.output_cols = output_cols\n",
    "        self.lr = lr\n",
    "        \n",
    "        self.encoder = Encoder(n_x, vocab_col, vocab_size, hidden_size)\n",
    "        self.att = Attention()\n",
    "        self.decoder = Decoder()\n",
    "        \n",
    "        self.ff1 = nn.Linear(2*hidden_size, 4*hidden_size)\n",
    "        self.drop1 = nn.Dropout(dropout_rate)\n",
    "        self.ff2 = nn.Linear(4*hidden_size, n_y, bias=False)\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        out_vec = self.ff2(self.drop1(F.relu(self.ff1(out_vec))))\n",
    "        return out_vec\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y, lengths = batch\n",
    "        y_hat = self.forward(x, y)\n",
    "        print(y_hat[1,1,:])\n",
    "        return {'loss': F.mse_loss(y_hat, torch.FloatTensor(y))}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, lengths = batch\n",
    "        y_hat = self.forward(x, y)\n",
    "        return {'loss': F.mse_loss(y_hat, torch.FloatTensor(y))}\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return dl.DataGenerator(train, self.seq_length, batch_size=self.batch_size, output_cols=self.output_cols)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return dl.DataGenerator(val, self.seq_length, batch_size=self.batch_size, output_cols=self.output_cols)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.25)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def generate_mask(self, sz, for_input=False):\n",
    "        diag = 0 if for_input else 1 \n",
    "        mask = (torch.triu(torch.ones(sz, sz), diagonal=diag) == 1).transpose(0, 1)\n",
    "#         mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(200, train[0][0].shape[1], len(output_cols),\n",
    "            vocab_col=train[0][0].columns.get_loc(\"pitch\"),\n",
    "            vocab_size=len(ix_to_lex) + 3, \n",
    "            batch_size=64, \n",
    "            hidden_size=32,\n",
    "            dropout_rate=0.1,\n",
    "            output_cols=['ioiRatio', 'peakLevel'],\n",
    "            lr=3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jB1zXiP9IxLV"
   },
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "colab_type": "code",
    "id": "JpghmUE3IxLX",
    "outputId": "6c2e7186-6bf7-41ac-ea28-387da0e9d393"
   },
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(max_epochs=1)\n",
    "trainer.fit(model)\n",
    "\n",
    "#  Save model\n",
    "torch.save(model.state_dict(), pathRoot + '2021-01-11-test0.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mv-wgSVTIxLj"
   },
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J2eV2YV0IxL1",
    "outputId": "2af81d2a-bd9b-47a8-a0d3-038baaf6e948"
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "# model.load_state_dict(torch.load(pathRoot + '2021-01-11-test0.pth'))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "#  Compute note-level error\n",
    "\n",
    "# use validation data\n",
    "# test = val\n",
    "\n",
    "# use test data\n",
    "with open(os.path.join(pathRoot, 'LvB_test_sequences.data'), 'rb') as seq_path:\n",
    "    test = pickle.load(seq_path)\n",
    "\n",
    "### CORRECT BELOW\n",
    "    \n",
    "def evaluation(sequences, sequence_length, model, pad_value=0.):\n",
    "    Yhat = []\n",
    "    for S in sequences:\n",
    "        X = S[0]\n",
    "        tx = X.shape[0]\n",
    "        n_x = int(tx / sequence_length)\n",
    "        n_x += 0 if tx % sequence_length == 0 else 1\n",
    "        x = np.full((n_x, sequence_length, X.shape[1]), pad_value)\n",
    "        for i in range(n_x - 1):            \n",
    "            x[i,:,:] = X.iloc[(i * sequence_length):(i + 1) * sequence_length,:].to_numpy()\n",
    "        x[n_x - 1,:tx - (n_x - 1) * sequence_length,:] = X.iloc[(n_x - 1) * sequence_length:,:].to_numpy()\n",
    "        y = model(x)\n",
    "        print(y.shape)\n",
    "        Yhat.append(y.reshape((-1,y.shape[2])))\n",
    "    return Yhat\n",
    "\n",
    "def sliding_evaluation(sequences, sequence_length, model, pad_value=0., pad_start=True):\n",
    "    Yhat = []\n",
    "    for S in sequences:\n",
    "        X = S[0]\n",
    "        tx = X.shape[0]\n",
    "        n_x = tx if pad_start else tx - sequence_length + 1\n",
    "        x = np.full((n_x, sequence_length, X.shape[1]), pad_value)\n",
    "        idx = 0\n",
    "        if pad_start:\n",
    "            for i in range(0, sequence_length):\n",
    "                x[i,sequence_length-i-1:,:] = X.iloc[0:i+1,:].to_numpy()\n",
    "            idx = sequence_length\n",
    "        else:\n",
    "            x[0,:,:] = X.iloc[0:sequence_length,:].to_numpy()\n",
    "            idx = 1\n",
    "        for i in range(1, tx - sequence_length):\n",
    "            x[idx,:,:] = X.iloc[i:i+sequence_length,:].to_numpy()\n",
    "            idx += 1\n",
    "        y = model.predict(x)\n",
    "        if y.ndim < 3:  # single timestep prediction\n",
    "            Yhat.append(y)\n",
    "        elif pad_start:\n",
    "            Yhat.append(y[:,-1,:])\n",
    "        else:\n",
    "            Yhat.append(np.concatenate((y[0,:,:], y[1:, -1, :])))\n",
    "    return Yhat\n",
    "\n",
    "Yhat = evaluation(test_sequences, seq_length, model)\n",
    "mse = np.zeros((len(test_sequences), Yhat[0].shape[1]))\n",
    "ms = np.zeros((len(test_sequences), Yhat[0].shape[1]))\n",
    "for i, (_, Y, _, _, _) in enumerate(test_sequences):\n",
    "    Y = Y.loc[:,output_cols]\n",
    "    mse[i,:] = np.mean((Yhat[i][:Y.shape[0],:] - Y) ** 2)\n",
    "    ms[i,:] = np.mean(Y ** 2)\n",
    "    \n",
    "print('Validation set MSE for y_0: ' + str(np.mean(mse[:,0])) + '     mean square val: ' + str(np.mean(ms[:,0])))\n",
    "print('Minimum y_0 MSE among pieces: ' + str(mse[:,0].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(mse[:,0])\n",
    "plt.plot(ms[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "piece = 0\n",
    "attr = ['peakLevel']\n",
    "plt.figure(figsize=(21, 5))\n",
    "plt.plot(Yhat[piece][:,0])\n",
    "plt.plot(test_sequences[piece][1].loc[:,attr].to_numpy())\n",
    "# print(test_sequences[piece][1].columns[attr])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listen to a synthesized predicted expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import IPython.display\n",
    "\n",
    "test_sequences = val\n",
    "\n",
    "# piece to synthesize:\n",
    "pieceNum = 27\n",
    "pieceId = test_sequences[pieceNum][2]\n",
    "print(pieceId)\n",
    "\n",
    "deviations_pred = Yhat[pieceNum][:,0] * test_sequences[pieceNum][4][2,1] + test_sequences[pieceNum][4][2,0]\n",
    "deviations_perf = test_sequences[pieceNum][1].ioiRatio * test_sequences[pieceNum][4][2,1] + test_sequences[pieceNum][4][2,0]\n",
    "tempo = test_sequences[pieceNum][1].localTempo.iloc[0] * test_sequences[pieceNum][4][0,1] + test_sequences[pieceNum][4][0,0]\n",
    "no_dev = [test_sequences[pieceNum][4][2,0]] * test_sequences[pieceNum][1].shape[0]\n",
    "dev_rand = np.random.normal(size=test_sequences[pieceNum][1].shape[0]) * test_sequences[pieceNum][4][2,1] + test_sequences[pieceNum][4][2,0]\n",
    "pm = pretty_midi.PrettyMIDI(initial_tempo=60 * tempo)\n",
    "inst = pretty_midi.Instrument(program=test_sequences[pieceNum][3], is_drum=False, name='melody_inst')\n",
    "pm.instruments.append(inst)\n",
    "start = 0.\n",
    "lastNote = None\n",
    "for x, y, dev in zip(test_sequences[pieceNum][0].itertuples(), test_sequences[pieceNum][1].itertuples(), deviations_perf):\n",
    "    (pitch, _) = ix_to_lex[x.melody]\n",
    "    if lastNote:\n",
    "        if start < lastNote.end:\n",
    "            lastNote.end = start\n",
    "    end = start + (x.duration * moments['duration'][1] + moments['duration'][0]) * dev\n",
    "    lastNote = pretty_midi.Note(100, pitch, start, end)\n",
    "    inst.notes.append(lastNote)\n",
    "    start += (x.ioi * moments['ioi'][1] + moments['ioi'][0]) * dev\n",
    "IPython.display.Audio(pm.fluidsynth(fs=44100), rate=44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building conductive input from generated performance\n",
    "\n",
    "This step uses the predicted timing information to build a local tempo signal which can be used as input in a virtual conductor. That signal is compared to the local tempo vector obtained from the chosen reference performance from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "PhraseDynamicsLSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
