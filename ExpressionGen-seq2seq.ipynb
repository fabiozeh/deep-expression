{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gs2Yk5y3IxKb"
   },
   "source": [
    "Deep artificial neural network for expressive timing and dynamics predictions in musical pieces\n",
    "---------------\n",
    "\n",
    "This notebook loads a sequential dataset with score and performance information and uses it to train and test a deep artificial neural network for generating onset timing deviation and peak loudness level of notes from musical pieces.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing to install XLA (for training on TPUs) and pytorch-lightning (skip if not using Google Colab):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "\n",
    "!python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install pytorch_lightning --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters to set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runLocal = True  # set to False for using Google Colab\n",
    "\n",
    "output_cols = [\"peakLevel\"]\n",
    "DEV_RUN = False\n",
    "SCHEDULER_STEP_SIZE = 4\n",
    "SCHEDULER_GAMMA = 0.25\n",
    "LR = 1e-6\n",
    "SEQ_LEN = 200\n",
    "HIDDEN_SIZE = 128\n",
    "DROPOUT = 0.1\n",
    "EVAL_STRIDE = 160 #int(SEQ_LEN / 2)  # score notes sliding window\n",
    "EVAL_CTX = 20 #int(EVAL_STRIDE / 2)  # no. of note predictions to ignore in sequence start\n",
    "PAD_END = True\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 8\n",
    "STATE_DICT_NAME = 'hpc_logs/version_2137133/2021-03-06-hp200-128-lvl.pth'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting path and loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "\n",
    "if runLocal:\n",
    "    pathRoot = 'data/'\n",
    "else:\n",
    "    pathRoot = '/content/drive/My Drive/colab_data/'\n",
    "    !wget \"https://raw.githubusercontent.com/fabiozeh/deep-expression/master/dataloader.py\"\n",
    "    !wget \"https://raw.githubusercontent.com/fabiozeh/deep-expression/master/seq2seq.py\"\n",
    "\n",
    "    \n",
    "with open(os.path.join(pathRoot, 'LvB_train_sequences.data'), 'rb') as seq_path:\n",
    "    train = pickle.load(seq_path)\n",
    "with open(os.path.join(pathRoot, 'LvB_val_sequences.data'), 'rb') as seq_path:\n",
    "    val = pickle.load(seq_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DzL3Y9MOIxLG"
   },
   "source": [
    "#### Defining the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import seq2seq\n",
    "\n",
    "with open(pathRoot + 'LvB_pitch_dict.data', 'rb') as filehandle:\n",
    "    lex_to_ix = pickle.load(filehandle)\n",
    "    ix_to_lex = {v: k for k, v in lex_to_ix.items()}\n",
    "with open(pathRoot + 'LvB_normalizer.data', 'rb') as filehandle:\n",
    "    moments, cols = pickle.load(filehandle)\n",
    "    moments = dict(zip(cols, list(moments)))\n",
    "with open(os.path.join(pathRoot, 'LvB_test_sequences.data'), 'rb') as seq_path:\n",
    "    test = pickle.load(seq_path)\n",
    "\n",
    "model = seq2seq.Net(test[0][0][0].shape[1],\n",
    "            len(output_cols),\n",
    "            vocab_size=len(ix_to_lex) + 4,  # 0 = pad, len+1 = UKN, len+2 = END, len+3 = SOS\n",
    "            hidden_size=HIDDEN_SIZE,\n",
    "            dropout_rate=DROPOUT,\n",
    "            lr=LR,\n",
    "            context=(EVAL_CTX if PAD_END else 0),\n",
    "            window=(EVAL_STRIDE if PAD_END else 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jB1zXiP9IxLV"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "colab_type": "code",
    "id": "JpghmUE3IxLX",
    "outputId": "6c2e7186-6bf7-41ac-ea28-387da0e9d393"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import dataloader as dl\n",
    "\n",
    "if runLocal:\n",
    "    trainer = pl.Trainer(max_epochs=NUM_EPOCHS, fast_dev_run=DEV_RUN, val_check_interval=0.25)\n",
    "    workers = 4\n",
    "else:\n",
    "    trainer = pl.Trainer(gpus=1, accelerator='dp', fast_dev_run=DEV_RUN,\n",
    "                         progress_bar_refresh_rate=20, max_epochs=NUM_EPOCHS,\n",
    "                         val_check_interval=0.25)\n",
    "    workers = 0\n",
    "\n",
    "if SEQ_LEN == 0:\n",
    "    train_ds = dl.FullPieceDataset(train, \n",
    "                                   vocab_col=test[0][0][0].columns.get_loc(\"pitch\"),\n",
    "                                   output_cols=output_cols)\n",
    "    val_ds = dl.FullPieceDataset(val, \n",
    "                                 vocab_col=test[0][0][0].columns.get_loc(\"pitch\"),\n",
    "                                 output_cols=output_cols)\n",
    "else:\n",
    "    train_ds = dl.TrainDataset(train, \n",
    "                               vocab_col=test[0][0][0].columns.get_loc(\"pitch\"),\n",
    "                               sequence_length=SEQ_LEN,\n",
    "                               output_cols=output_cols,\n",
    "                               context=EVAL_CTX,\n",
    "                               dummy=DEV_RUN)\n",
    "    val_ds = dl.ValidationDataset(val, \n",
    "                                  vocab_col=test[0][0][0].columns.get_loc(\"pitch\"),\n",
    "                                  sequence_length=SEQ_LEN,\n",
    "                                  output_cols=output_cols,\n",
    "                                  stride=EVAL_STRIDE,\n",
    "                                  context=EVAL_CTX,\n",
    "                                  pad_both_ends=PAD_END,\n",
    "                                  device=model.device)\n",
    "trainer.fit(model, \n",
    "            DataLoader(train_ds,\n",
    "                       batch_size=BATCH_SIZE,\n",
    "                       num_workers = workers,\n",
    "                       shuffle=True,\n",
    "                       collate_fn=dl.TrainDataset.collate_fn),\n",
    "            DataLoader(val_ds,\n",
    "                       batch_size=None,\n",
    "                       num_workers=workers))\n",
    "\n",
    "#  Save model\n",
    "torch.save(model.state_dict(), pathRoot + STATE_DICT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mv-wgSVTIxLj"
   },
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J2eV2YV0IxL1",
    "outputId": "2af81d2a-bd9b-47a8-a0d3-038baaf6e948"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import dataloader as dl\n",
    "\n",
    "\n",
    "# Load model\n",
    "model.load_state_dict(torch.load(STATE_DICT_NAME))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "Yhat, mse = seq2seq.evaluation(val, SEQ_LEN, model, stride=EVAL_STRIDE, output_cols=output_cols,\n",
    "                               context=EVAL_CTX, pad_both_ends=PAD_END)\n",
    "    \n",
    "for i, col in enumerate(output_cols):\n",
    "    print('Validation set MSE for ' + col + ': ' + str(np.mean(mse[:, i])))\n",
    "    print('Minimum MSE among pieces for ' + col + ': ' + str(mse[:, i].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "piece = 0\n",
    "attr = ['peakLevel']\n",
    "plt.figure(figsize=(21, 5))\n",
    "plt.plot(Yhat[piece][:200,0])\n",
    "plt.plot(test[piece][0][1].loc[:,attr].to_numpy()[:200])\n",
    "# print(test_sequences[piece][1].columns[attr])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of dynamics of different performances of same piece for context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(21, 5))\n",
    "plt.plot(train[35][0][1].loc[:,attr].to_numpy()[2500:])\n",
    "plt.plot(train[70][0][1].loc[:,attr].to_numpy()[2500:])\n",
    "plt.figure(figsize=(21, 5))\n",
    "plt.plot(train[42][0][1].loc[:,attr].to_numpy()[1000:1300])\n",
    "plt.plot(train[77][0][1].loc[:,attr].to_numpy()[1000:1300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_human1 = np.mean((train[70][0][1].loc[:, 'peakLevel'].iloc[:3120].to_numpy('float64') - train[35][0][1].loc[:, 'peakLevel'].iloc[:3120].to_numpy('float64')) ** 2)\n",
    "mse_human2 = np.mean((train[42][0][1].loc[:, 'peakLevel'].to_numpy('float64') - train[77][0][1].loc[:, 'peakLevel'].to_numpy('float64')) ** 2)\n",
    "\n",
    "print(\"MSE between two performances of sonata 7, 2nd mvmt.: \" + str(mse_human1))\n",
    "print(\"MSE between two performances of sonata 7, 3rd mvmt.: \" + str(mse_human2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listen to a piece synthesized with the generated expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import IPython.display\n",
    "import expression_modeling as m\n",
    "\n",
    "# piece to synthesize:\n",
    "pieceNum = 0\n",
    "pieceId = val[pieceNum][1]\n",
    "print(pieceId)\n",
    "\n",
    "pred = Yhat[pieceNum][:,0]\n",
    "ref = val[pieceNum][0][1].ioiRatio\n",
    "no_dev = np.asarray([val[pieceNum][0][2][2,0]] * val[pieceNum][0][1].shape[0])\n",
    "dev_rand = np.random.normal(size=val[pieceNum][0][1].shape[0]) * val[pieceNum][0][2][2,1] + val[pieceNum][0][2][2,0]\n",
    "\n",
    "pm = m.midi_performance(val[pieceNum][0], pred, moments, ix_to_lex, method='ioiRatio')\n",
    "IPython.display.Audio(pm.fluidsynth(fs=44100), rate=44100)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "PhraseDynamicsLSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
