{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gs2Yk5y3IxKb"
   },
   "source": [
    "Deep artificial neural network for expressive timing and dynamics predictions in musical pieces\n",
    "---------------\n",
    "\n",
    "This notebook loads a sequential dataset with score and performance information and uses it to train and test a deep artificial neural network for generating onset timing deviation and peak loudness level of notes from musical pieces.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Start Here!\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "### Parameters to set:\n",
    "\n",
    "runLocal = True  # set to False for using Google Colab\n",
    "\n",
    "if runLocal:\n",
    "    pathRoot = 'data/'\n",
    "else:\n",
    "    pathRoot = '/content/drive/My Drive/colab_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing to use TPUs and pytorch-lightning (run if using Google Colab):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crash on purpose to get more ram :\n",
    "import torch\n",
    "torch.tensor([10.]*10000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install pytorch_lightning --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DzL3Y9MOIxLG"
   },
   "source": [
    "#### Define the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget \"https://raw.githubusercontent.com/fabiozeh/deep-expression/master/dataloader.py\"\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import dataloader as dl\n",
    "\n",
    "np.random.seed(1728)\n",
    "torch.manual_seed(1728)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, n_x, vocab_col, vocab_size, embed_size, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.vocab_col = vocab_col\n",
    "        self.pitchEmbedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_size, padding_idx=0)\n",
    "        self.harmonyRhythmProjector = nn.Linear(in_features=n_x - 1, out_features=embed_size)\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "        self.norm1 = nn.LayerNorm(2*embed_size)\n",
    "        self.rnn = nn.GRU(2 * embed_size, 2 * embed_size, num_layers=1, bidirectional=True)\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "        self.norm2 = nn.LayerNorm(4*embed_size)\n",
    "    \n",
    "    def forward(self, x, lengths):\n",
    "        pitch = torch.LongTensor(x[:, :, self.vocab_col])\n",
    "        harmRhythm = torch.cat([torch.FloatTensor(x[:,:,:self.vocab_col]), torch.FloatTensor(x[:,:,self.vocab_col+1:])], dim=2)\n",
    "        lengths = torch.LongTensor(lengths).view(-1)\n",
    "        \n",
    "        pitch = self.pitchEmbedding(pitch)\n",
    "        harmRhythm = self.harmonyRhythmProjector(harmRhythm)\n",
    "        src_vec = torch.cat([pitch, harmRhythm], dim=2)\n",
    "        src_vec = self.norm1(self.drop1(src_vec))\n",
    "        sequence = nn.utils.rnn.pack_padded_sequence(src_vec, lengths, enforce_sorted=False)\n",
    "        output, _ = self.rnn(sequence)\n",
    "        output, _ = nn.utils.rnn.pad_packed_sequence(output)\n",
    "        return self.norm2(self.drop2(output))\n",
    "    \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, n_y, hidden_size, enc_hidden_size, dropout=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.y_proj = nn.Linear(n_y, hidden_size)\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "        self.attention = nn.MultiheadAttention(hidden_size, 1, kdim=enc_hidden_size, vdim=enc_hidden_size)\n",
    "        self.rnn = nn.GRU(2*hidden_size, hidden_size, num_layers=1)\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "        self.norm = nn.LayerNorm(hidden_size)\n",
    "        self.ff1 = nn.Linear(3*hidden_size, 2*hidden_size)\n",
    "        self.drop3 = nn.Dropout(dropout)\n",
    "        self.ff2 = nn.Linear(2*hidden_size, n_y, bias=False)\n",
    "        \n",
    "    def forward(self, y_prev, encoder_out, dec_hidden):\n",
    "        \"\"\"\n",
    "        Generates outputs for a single step in the sequence (one note)\n",
    "        \"\"\"\n",
    "        y_projected = self.drop1(self.y_proj(y_prev))  # (1, batch_size, hidden_size)\n",
    "        \n",
    "        # shapes: (1, b, h) <- ( (1, b, h), (len_seq, b, enc_hidden), (len_seq, b, enc_hidden) )\n",
    "        context, _ = self.attention(dec_hidden, encoder_out, encoder_out)\n",
    "        rnn_out, new_dec_hidden = self.rnn(torch.cat([y_projected, context], dim=2), dec_hidden)\n",
    "        \n",
    "        rnn_out = self.norm(self.drop2(rnn_out))\n",
    "        out = self.ff2(self.drop3(F.relu(self.ff1(torch.cat([rnn_out, y_projected, context], dim=2)))))\n",
    "        return out, new_dec_hidden\n",
    "\n",
    "class Net(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, seq_length, n_x, n_y, vocab_col, vocab_size, batch_size, \n",
    "                 hidden_size, dropout_rate, output_cols, lr):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        assert hidden_size % 2 == 0, \"hidden_size must be multiple of 2\"\n",
    "        \n",
    "        self.n_y = n_y\n",
    "        self.seq_length = seq_length\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_cols = output_cols\n",
    "        self.lr = lr\n",
    "        self.rng = np.random.default_rng()\n",
    "        \n",
    "        self.encoder = Encoder(n_x, vocab_col, vocab_size, int(hidden_size/2), dropout_rate)\n",
    "        self.decoder = Decoder(n_y, hidden_size, 2*hidden_size, dropout_rate)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "        \"\"\"\n",
    "        Generate the entire sequence \n",
    "        \"\"\"\n",
    "        encoded_score = self.encoder(x, lengths)\n",
    "        hidden = torch.zeros((1, x.shape[1], self.hidden_size))\n",
    "        y = torch.zeros((x.shape[0], x.shape[1], self.n_y))\n",
    "        prev_y = torch.zeros((1, x.shape[1], self.n_y))\n",
    "        for i in range(x.shape[0]):\n",
    "            prev_y, hidden = self.decoder(prev_y, encoded_score, hidden)\n",
    "            y[i,:,:] = prev_y\n",
    "        return y\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        This method doesn't use self.forward directly so we can apply teacher forcing\n",
    "        on a fraction of the steps.\n",
    "        \"\"\"\n",
    "        x, y, lengths = batch\n",
    "        # encode x (score)\n",
    "        encoded_score = self.encoder(x, lengths)\n",
    "        \n",
    "        # iterate generating y\n",
    "        teacher_forcing_ratio = 0.5\n",
    "        \n",
    "        y = torch.FloatTensor(y)\n",
    "        hidden = torch.zeros((1, x.shape[1], self.hidden_size))\n",
    "        y_hat = torch.zeros((x.shape[0], x.shape[1], self.n_y))\n",
    "        prev_y = torch.zeros((1, x.shape[1], self.n_y))\n",
    "        for i in range(x.shape[0]):\n",
    "            prev_y, hidden = self.decoder(prev_y, encoded_score, hidden)\n",
    "            y_hat[i,:,:] = prev_y\n",
    "            if self.rng.random() > teacher_forcing_ratio:\n",
    "                prev_y = y[i,:,:].view(1, -1, self.n_y)\n",
    "        loss =  F.mse_loss(y_hat, y)\n",
    "        tensorboard_logs = {'train_loss': loss}\n",
    "        return {'loss': loss, 'log': tensorboard_logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, lengths = batch\n",
    "        \n",
    "        y_hat = self.forward(x, lengths)\n",
    "        return {'val_loss': F.mse_loss(y_hat, torch.FloatTensor(y))}\n",
    "\n",
    "    def prepare_data(self):\n",
    "        with open(os.path.join(pathRoot, 'LvB_val_sequences.data'), 'rb') as seq_path:\n",
    "            self.train = pickle.load(seq_path)\n",
    "        with open(os.path.join(pathRoot, 'LvB_test_sequences.data'), 'rb') as seq_path:\n",
    "            self.val = pickle.load(seq_path)\n",
    "        with open(pathRoot + 'LvB_pitch_dict.data', 'rb') as filehandle:\n",
    "            self.lex_to_ix = pickle.load(filehandle)\n",
    "            self.ix_to_lex = {v: k for k, v in self.lex_to_ix.items()}\n",
    "        with open(pathRoot + 'LvB_normalizer.data', 'rb') as filehandle:\n",
    "            self.moments, self.cols = pickle.load(filehandle)\n",
    "            self.moments = dict(zip(self.cols, list(self.moments)))\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return dl.DataGenerator(self.train, self.seq_length, batch_size=self.batch_size, output_cols=self.output_cols)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return dl.DataGenerator(self.val, self.seq_length, batch_size=self.batch_size, output_cols=self.output_cols)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.25)\n",
    "        return [optimizer], [scheduler]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_cols = ['ioiRatio', 'peakLevel']\n",
    "\n",
    "model = Net(50, train[0][0][0].shape[1], len(output_cols),\n",
    "            vocab_col=train[0][0][0].columns.get_loc(\"pitch\"),\n",
    "            vocab_size=len(ix_to_lex) + 3, \n",
    "            batch_size=32, \n",
    "            hidden_size=32,\n",
    "            dropout_rate=0.1,\n",
    "            output_cols=output_cols,\n",
    "            lr=3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jB1zXiP9IxLV"
   },
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "colab_type": "code",
    "id": "JpghmUE3IxLX",
    "outputId": "6c2e7186-6bf7-41ac-ea28-387da0e9d393"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name    | Type    | Params\n",
      "------------------------------------\n",
      "0 | encoder | Encoder | 53 K  \n",
      "1 | decoder | Decoder | 87 K  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23aa97a7b8d1435ca2c18c27cf3d701a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(num_tpu_cores=8, progress_bar_refresh_rate=20, max_epochs=1)\n",
    "trainer.fit(model)\n",
    "\n",
    "#  Save model\n",
    "torch.save(model.state_dict(), pathRoot + '2021-01-29-test0.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start tensorboard.\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mv-wgSVTIxLj"
   },
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J2eV2YV0IxL1",
    "outputId": "2af81d2a-bd9b-47a8-a0d3-038baaf6e948"
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "# model.load_state_dict(torch.load(pathRoot + '2021-01-11-test0.pth'))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "#  Compute note-level error\n",
    "\n",
    "# use validation data\n",
    "# test = val\n",
    "\n",
    "# use test data\n",
    "with open(os.path.join(pathRoot, 'LvB_test_sequences.data'), 'rb') as seq_path:\n",
    "    test = pickle.load(seq_path)\n",
    "\n",
    "### CORRECT BELOW\n",
    "    \n",
    "def evaluation(sequences, sequence_length, model, pad_value=0.):\n",
    "    Yhat = []\n",
    "    for S in sequences:\n",
    "        X = S[0][0]\n",
    "        tx = X.shape[0]\n",
    "        n_x = int(tx / sequence_length)\n",
    "        n_x += 0 if tx % sequence_length == 0 else 1\n",
    "        x = np.full((sequence_length, n_x, X.shape[1]), pad_value)\n",
    "        for i in range(n_x - 1):            \n",
    "            x[:,i,:] = X.iloc[(i * sequence_length):(i + 1) * sequence_length,:].to_numpy()\n",
    "        x[:tx - (n_x - 1) * sequence_length,n_x - 1,:] = X.iloc[(n_x - 1) * sequence_length:,:].to_numpy()\n",
    "        y = model(x, n_x*[sequence_length])\n",
    "        print(y.shape)\n",
    "        Yhat.append(y.detach().numpy().reshape((-1,y.shape[2])))\n",
    "    return Yhat\n",
    "\n",
    "def sliding_evaluation(sequences, sequence_length, model, pad_value=0., pad_start=True):\n",
    "    Yhat = []\n",
    "    for S in sequences:\n",
    "        X = S[0]\n",
    "        tx = X.shape[0]\n",
    "        n_x = tx if pad_start else tx - sequence_length + 1\n",
    "        x = np.full((n_x, sequence_length, X.shape[1]), pad_value)\n",
    "        idx = 0\n",
    "        if pad_start:\n",
    "            for i in range(0, sequence_length):\n",
    "                x[i,sequence_length-i-1:,:] = X.iloc[0:i+1,:].to_numpy()\n",
    "            idx = sequence_length\n",
    "        else:\n",
    "            x[0,:,:] = X.iloc[0:sequence_length,:].to_numpy()\n",
    "            idx = 1\n",
    "        for i in range(1, tx - sequence_length):\n",
    "            x[idx,:,:] = X.iloc[i:i+sequence_length,:].to_numpy()\n",
    "            idx += 1\n",
    "        y = model(x)\n",
    "        if pad_start:\n",
    "            Yhat.append(y[:,-1,:])\n",
    "        else:\n",
    "            Yhat.append(np.concatenate((y[0,:,:], y[1:, -1, :])))\n",
    "    return Yhat\n",
    "\n",
    "Yhat = evaluation(test, 200, model)\n",
    "mse = np.zeros((len(test), Yhat[0].shape[1]))\n",
    "ms = np.zeros((len(test), Yhat[0].shape[1]))\n",
    "for i, S in enumerate(test):\n",
    "    Y = S[0][1]\n",
    "    Y = Y.loc[:,output_cols]\n",
    "    mse[i,:] = np.mean((Yhat[i][:Y.shape[0],:] - Y) ** 2)\n",
    "    ms[i,:] = np.mean(Y ** 2)\n",
    "    \n",
    "print('Validation set MSE for y_0: ' + str(np.mean(mse[:,0])) + '     mean square val: ' + str(np.mean(ms[:,0])))\n",
    "print('Minimum y_0 MSE among pieces: ' + str(mse[:,0].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(mse[:,0])\n",
    "plt.plot(ms[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "piece = 0\n",
    "attr = ['peakLevel']\n",
    "plt.figure(figsize=(21, 5))\n",
    "plt.plot(Yhat[piece][:,0])\n",
    "plt.plot(test[piece][0][1].loc[:,attr].to_numpy())\n",
    "# print(test_sequences[piece][1].columns[attr])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listen to a synthesized predicted expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import IPython.display\n",
    "\n",
    "test_sequences = val\n",
    "\n",
    "# piece to synthesize:\n",
    "pieceNum = 27\n",
    "pieceId = test[pieceNum][2]\n",
    "print(pieceId)\n",
    "\n",
    "deviations_pred = Yhat[pieceNum][:,0] * test[pieceNum][0][2][2,1] + test[pieceNum][0][2][2,0]\n",
    "deviations_perf = test[pieceNum][0][1].ioiRatio * test[pieceNum][0][2][2,1] + test[pieceNum][0][2][2,0]\n",
    "tempo = test[pieceNum][0][1].localTempo.iloc[0] * test[pieceNum][0][2][0,1] + test[pieceNum][0][2][0,0]\n",
    "no_dev = [test[pieceNum][0][2][2,0]] * test[pieceNum][0][1].shape[0]\n",
    "dev_rand = np.random.normal(size=test[pieceNum][0][1].shape[0]) * test[pieceNum][0][2][2,1] + test[pieceNum][0][2][2,0]\n",
    "pm = pretty_midi.PrettyMIDI(initial_tempo=60 * tempo)\n",
    "piano = pretty_midi.Instrument(1, is_drum=False, name='piano')\n",
    "violin = pretty_midi.Instrument(41, is_drum=False, name='violin')\n",
    "pm.instruments.append(piano)\n",
    "pm.instruments.append(violin)\n",
    "start = 0.\n",
    "prev_note = None\n",
    "for x, y, dev in zip(test[pieceNum][0][0].itertuples(), test_sequences[pieceNum][0][1].itertuples(), deviations_perf):\n",
    "    (pitch, _) = ix_to_lex[x.pitch]\n",
    "    start += (x.beatDiff * model.moments['beatDiff'][1] + model.moments['beatDiff'][0]) * dev\n",
    "    end = start + (x.duration * model.moments['duration'][1] + model.moments['duration'][0]) * dev\n",
    "    prev_note = pretty_midi.Note(100, pitch, start, end)\n",
    "    if x.instrument == 'instrument_1':\n",
    "        piano.notes.append(prev_note)\n",
    "    else:\n",
    "        violin.notes.append(prev_note)\n",
    "    \n",
    "IPython.display.Audio(pm.fluidsynth(fs=44100), rate=44100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building conductive input from generated performance\n",
    "\n",
    "This step uses the predicted timing information to build a local tempo signal which can be used as input in a virtual conductor. That signal is compared to the local tempo vector obtained from the chosen reference performance from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "PhraseDynamicsLSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
