{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note-level sequence generation\n",
    "\n",
    "This notebook uses note-level data from the MusicNet dataset to set up sequential arrays suitable for training deep neural networks.\n",
    "\n",
    "**Before running:** Make sure to generate the appropriate csv files using the note-level processing notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### START HERE ####\n",
    "\n",
    "dataFolder = 'data/'  # make sure the path to data folder is correct\n",
    "is_training_set = True "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Note Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial size: 40838\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(1728)\n",
    "\n",
    "#  read csv\n",
    "if is_training_set:\n",
    "    with open(dataFolder + 'per_note_train.csv', 'r') as path:\n",
    "        df = pd.read_csv(path)\n",
    "else:\n",
    "    with open(dataFolder + 'per_note_test.csv', 'r') as path:\n",
    "        df = pd.read_csv(path)\n",
    "\n",
    "df.drop(['Unnamed: 0', 'bassNote', 'probChord_I', 'probChord_II', 'probChord_III',\n",
    "         'probChord_IV', 'probChord_V', 'probChord_VI', 'probChord_VII', 'isDissonance'], axis=1, inplace=True)\n",
    "df['instrument'] = df['instrument'].astype(pd.CategoricalDtype([41, 42, 43, 72, 74]))\n",
    "print('initial size: ' + str(len(df)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping melodic and harmonic vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping melody vocabulary.\n",
      "vocabulary size = 657\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "melodies = list(df.loc[:,['pitch']].itertuples(index=False, name=None))\n",
    "harmonies = list(df.loc[:,['harmony']].itertuples(index=False, name=None))\n",
    "\n",
    "if is_training_set:\n",
    "    #  generate vocabulary of (pitch, bassNote)\n",
    "\n",
    "    print(\"Mapping melody vocabulary.\")\n",
    "    voc_mel = list(set(melodies))\n",
    "    print('vocabulary size = ' + str(len(voc_mel)))\n",
    "    m_lex_to_ix = { lex:i+1 for i,lex in enumerate(voc_mel) } # index 0 is vacant for masking\n",
    "    \n",
    "    print(\"Mapping harmony vocabulary.\")\n",
    "    voc_harm = list(set(harmonies))\n",
    "    print('vocabulary size = ' + str(len(voc_harm)))\n",
    "    h_lex_to_ix = { lex:i+1 for i,lex in enumerate(voc_harm) } # index 0 is vacant for masking \n",
    "    \n",
    "    with open(dataFolder + 'mel_harm_dict.data', 'wb') as filehandle:\n",
    "        pickle.dump((m_lex_to_ix, h_lex_to_ix), filehandle)\n",
    "else:\n",
    "    with open(dataFolder + 'mel_harm_dict.data', 'rb') as filehandle:\n",
    "        m_lex_to_ix, h_lex_to_ix = pickle.load(filehandle)\n",
    "\n",
    "df['harmony'] = [h_lex_to_ix.get(h, len(h_lex_to_ix) + 1) for h in harmonies]\n",
    "df['melody'] = [m_lex_to_ix.get(m, len(m_lex_to_ix) + 1) for m in melodies]\n",
    "df.drop(['pitch'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arranging data for sequential training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pieces: 7\n"
     ]
    }
   ],
   "source": [
    "def sequencer(df, one_hot_cols=None):\n",
    "    sequences = []\n",
    "    maxLen = 0\n",
    "    #  list the pieces\n",
    "    pieces = set(df.pieceId)\n",
    "    for p in pieces:\n",
    "        # list the instruments\n",
    "        piece_seq = []\n",
    "        dp = df.loc[df.pieceId == p, :].copy()\n",
    "        instruments = set(dp.instrument)\n",
    "        for i in instruments:\n",
    "            di = dp.loc[dp.instrument == i, :].copy()\n",
    "            for tr in range(-3,4):\n",
    "                d = di.loc[di.transposition == tr, :].copy()\n",
    "                maxLen = len(d) if len(d) > maxLen else maxLen\n",
    "                d.drop(['pieceId', 'transposition'], axis=1, inplace=True)\n",
    "                \n",
    "                #  convert categories to one-hot\n",
    "                if one_hot_cols:\n",
    "                    for attrib in one_hot_cols:\n",
    "                        d = pd.concat([d, pd.get_dummies(d[attrib], prefix=attrib)], axis=1)\n",
    "                        d.drop([attrib], axis=1, inplace=True)\n",
    "                \n",
    "                #  instance standardization for relevant features\n",
    "                feats = ['localTempo', 'peakLevel']\n",
    "                aux = d.loc[:, feats]\n",
    "                moments = np.zeros((aux.shape[1], 2))\n",
    "                moments[:, 0] = aux.mean().to_numpy()\n",
    "                moments[:, 1] = aux.std().to_numpy()\n",
    "                d.loc[:, feats] = (aux - moments[:,0])/ moments[:,1]\n",
    "                \n",
    "                #  separate output features\n",
    "                outCols = ['ioiRatio', 'timingDev', 'timingDevLocal', 'localTempo', 'peakLevel', 'startTime', 'durationSecs']\n",
    "                y = d.loc[:, outCols].copy()\n",
    "                d.drop(outCols, axis=1, inplace=True)\n",
    "                \n",
    "                #  add <END> token to sequence\n",
    "                endx = pd.DataFrame(np.zeros((1,d.shape[1])), columns=d.columns)\n",
    "                endy = pd.DataFrame(np.zeros((1,y.shape[1])), columns=y.columns)\n",
    "                endx[\"melody\"] = len(m_lex_to_ix) + 2\n",
    "                endx[\"harmony\"] = len(h_lex_to_ix) + 2\n",
    "                d = d.append(endx)\n",
    "                y = y.append(endy)\n",
    "                \n",
    "                piece_seq.append((d, y, tr, i, moments))\n",
    "        sequences.append((piece_seq, p))\n",
    "    return sequences\n",
    "\n",
    "def standardize(df, moments=None, cols=None):\n",
    "    if cols is None:\n",
    "        cols = (df.dtypes == 'float64')\n",
    "    nums = df.loc[:,cols]\n",
    "    if moments is None:\n",
    "        moments = np.zeros((nums.shape[1],2)) # output mean and std for reverting predictions\n",
    "        moments[:,0] = nums.mean().to_numpy()\n",
    "        moments[:,1] = nums.std().to_numpy()\n",
    "    df.loc[:, cols] = (nums - moments[:,0]) / moments[:,1]\n",
    "    return moments, cols\n",
    "\n",
    "if is_training_set:\n",
    "    moments, cols = standardize(df, cols=['duration', 'ioi', 'ioiRatio', 'startTime', 'durationSecs', 'timingDev', 'timingDevLocal'])\n",
    "    with open(dataFolder + 'normalizer.data', 'wb') as filehandle:\n",
    "        pickle.dump((moments, cols), filehandle)\n",
    "else:\n",
    "    with open(dataFolder + 'normalizer.data', 'rb') as filehandle:\n",
    "        moments, cols = pickle.load(filehandle)\n",
    "    standardize(df, moments=moments, cols=cols)\n",
    "\n",
    "sequences = sequencer(df, one_hot_cols=['instrument'])\n",
    "\n",
    "print(\"Number of pieces: \" + str(len(sequences)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#  Save arrays\n",
    "if is_training_set:\n",
    "    with open(dataFolder + 'mel_harm_sequences.data', 'wb') as filehandle:\n",
    "        pickle.dump(sequences, filehandle)\n",
    "else:\n",
    "    with open(dataFolder + 'mel_harm_sequences_test.data', 'wb') as filehandle:\n",
    "        pickle.dump(sequences, filehandle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
