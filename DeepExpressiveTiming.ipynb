{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gs2Yk5y3IxKb"
   },
   "source": [
    "Deep artificial neural network for expressive timing predictions in musical pieces\n",
    "---------------\n",
    "\n",
    "This notebook loads the data generated from the note level processing notebook and uses them to train and test a long sequence-based artificial neural network for predicting the onset timing deviation of notes from the MusicNet dataset pieces.\n",
    "\n",
    "\n",
    "#### Load and preprocess training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "5sQCWWMtIxKg",
    "outputId": "c0937385-1926-4992-ccd9-6dba03c3e71a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "np.random.seed(1728)\n",
    "\n",
    "#  read dataset\n",
    "runLocal = True\n",
    "if runLocal:\n",
    "    pathRoot = 'data/'\n",
    "else:\n",
    "    pathRoot = '/content/drive/My Drive/colab_data/'\n",
    "    \n",
    "df_path = open(pathRoot + 'per_note_train.csv', 'r')\n",
    "seq_path = open(pathRoot + 'note_sequences.data', 'rb')\n",
    "\n",
    "sequences = pickle.load(seq_path)\n",
    "\n",
    "seq_path.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DzL3Y9MOIxLG"
   },
   "source": [
    "#### Define the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "colab_type": "code",
    "id": "sOFtw2tuIxLJ",
    "outputId": "9a8f9a85-d095-4782-e5ac-b9e654083ea1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_5 (Bidirection (None, 20, 32)            15488     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 20, 32)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 20, 32)            128       \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 20, 3)             99        \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 20, 3)             12        \n",
      "=================================================================\n",
      "Total params: 15,727\n",
      "Trainable params: 15,657\n",
      "Non-trainable params: 70\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Input, Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dropout, BatchNormalization, Dense, TimeDistributed\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, data, sequence_length, batch_size=25, sequence_stride=1, shuffle=True, fit=True):\n",
    "        self.data = data\n",
    "        self.sequence_length = sequence_length\n",
    "        self.batch_size = batch_size\n",
    "        self.sequence_stride = sequence_stride\n",
    "        self.shuffle = shuffle\n",
    "        self.fit = fit\n",
    "        self.indexes = []\n",
    "        for si, (x, _, _) in enumerate(data):\n",
    "            tx = x.shape[0]\n",
    "            xind = 0\n",
    "            while tx > sequence_length:\n",
    "                self.indexes.append((si, xind))\n",
    "                xind += sequence_stride\n",
    "                tx -= sequence_stride\n",
    "            self.indexes.append((si,xind))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.indexes)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        (seq, stride) = self.indexes[index]\n",
    "        (X, Y, _) = self.data[seq]\n",
    "        if stride+self.sequence_length <= X.shape[0]:\n",
    "            if self.fit:\n",
    "                X = X.iloc[stride:stride+self.sequence_length, :].to_numpy(dtype='float64').reshape((1, self.sequence_length, X.shape[1]))\n",
    "                Y = Y.iloc[stride:stride+self.sequence_length, :].to_numpy(dtype='float64').reshape((1, self.sequence_length, Y.shape[1]))\n",
    "                return X, Y\n",
    "            else:\n",
    "                return X.iloc[stride:stride+self.sequence_length, :].to_numpy(dtype='float64').reshape((1, self.sequence_length, X.shape[1]))\n",
    "        else:\n",
    "            # pad\n",
    "            X = X.iloc[stride:X.shape[0], :].to_numpy(dtype='float64')\n",
    "            padX = np.full((self.sequence_length - X.shape[0], X.shape[1]), -1e4)\n",
    "            if self.fit:\n",
    "                Y = Y.iloc[stride:Y.shape[0], :].to_numpy(dtype='float64')\n",
    "                padY = np.full((self.sequence_length - Y.shape[0], Y.shape[1]), -1e4)\n",
    "                return np.concatenate((X, padX), axis=0).reshape((1, self.sequence_length, X.shape[1])), np.concatenate((Y, padY), axis=0).reshape((1, self.sequence_length, Y.shape[1]))\n",
    "            else:\n",
    "                return np.concatenate((X, padX), axis=0).reshape((1, self.sequence_length, X.shape[1]))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Updates indexes after each epoch\n",
    "        \"\"\"\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "            \n",
    "seq_length = 20        \n",
    "generator = DataGenerator(sequences, seq_length)\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(seq_length, sequences[0][0].shape[1])),\n",
    "    Bidirectional(LSTM(16, return_sequences = True)),\n",
    "    Dropout(0.8),\n",
    "    BatchNormalization(),\n",
    "    TimeDistributed(Dense(3)),\n",
    "    BatchNormalization()])\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=1e-4, clipnorm=0.001)\n",
    "model.compile(loss=\"mean_absolute_error\", optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jB1zXiP9IxLV"
   },
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "colab_type": "code",
    "id": "JpghmUE3IxLX",
    "outputId": "6c2e7186-6bf7-41ac-ea28-387da0e9d393"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "  9841/334002 [..............................] - ETA: 1:39:50 - loss: 0.7348"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(generator, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mv-wgSVTIxLj"
   },
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5oi_EZbPIxLn",
    "outputId": "99790f18-ce6c-49be-8a57-9d43ee7a5786"
   },
   "outputs": [],
   "source": [
    "#  Save model\n",
    "model.save_weights('timing2020-07-31.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J2eV2YV0IxL1",
    "outputId": "2af81d2a-bd9b-47a8-a0d3-038baaf6e948"
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "model.load_weights('timing2020-07-31.h5')\n",
    "\n",
    "#  Compute note-level error\n",
    "xval_s = 10\n",
    "Yhat = model.predict(X[0:xval_s,:,:])\n",
    "DynPieces = []\n",
    "DynIdeal = []\n",
    "DynHat = []\n",
    "RMSE_ideal = 0\n",
    "RMSE_pred = 0\n",
    "RMS_pieces = 0\n",
    "for choice in range(0,xval_s):\n",
    "    d_piece = np.load('data/levels/'+ str(df.pieceId[pd_idx[choice][0]]) + '_global_lvls.npy')\n",
    "    DynPieces.append(d_piece)\n",
    "    valid_idx = pd_idx[choice][pd_idx[choice] > 0]\n",
    "    ideal = np.zeros((len(d_piece),2))\n",
    "    hat = np.zeros((len(d_piece),2))\n",
    "    cur_idx = 0\n",
    "    for phr in range(len(valid_idx)):\n",
    "        duration = df.durationSecs[valid_idx[phr]]\n",
    "        t0 = df.startTime[valid_idx[phr]]\n",
    "        n = int(duration * 10)\n",
    "        tref = np.linspace(0, 1, n)\n",
    "        x2_ref = df.dynamicsX2[valid_idx[phr]]\n",
    "        x1_ref = df.dynamicsX1[valid_idx[phr]]\n",
    "        x0_ref = df.dynamicsX0[valid_idx[phr]]\n",
    "        x2_hat = Yhat[choice, phr, 0] * moments[choice,0,1] + moments[choice,0,0]\n",
    "        x1_hat = Yhat[choice, phr, 1] * moments[choice,1,1] + moments[choice,1,0]\n",
    "        x0_hat = Yhat[choice, phr, 2] * moments[choice,2,1] + moments[choice,2,0]\n",
    "        ideal[cur_idx:cur_idx + n, 0] = tref*duration + t0\n",
    "        ideal[cur_idx:cur_idx + n, 1] = x2_ref*tref**2 + x1_ref*tref + x0_ref\n",
    "        hat[cur_idx:cur_idx + n, 0] = tref*duration + t0\n",
    "        hat[cur_idx:cur_idx + n, 1] = x2_hat*tref**2 + x1_hat*tref + x0_hat\n",
    "        cur_idx += n\n",
    "    DynIdeal.append(ideal)\n",
    "    DynHat.append(hat)\n",
    "    RMSE_ideal += np.sqrt(np.mean((ideal[:,1] - d_piece)**2)) / xval_s\n",
    "    RMSE_pred += np.sqrt(np.mean((hat[:,1] - d_piece)**2)) / xval_s\n",
    "    RMS_pieces += np.sqrt(np.mean(d_piece**2)) / xval_s\n",
    "    \n",
    "print('Ideal approximation note-level RMS Error: ' + str(RMSE_ideal))\n",
    "print('Prediction note-level RMS Error: ' + str(RMSE_pred))\n",
    "print('Mean performance RMS loudness: ' + str(RMS_pieces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "choice = 3\n",
    "plt.figure(figsize=(21, 5))\n",
    "#plt.plot(np.asarray(list(range(0, len(DynPiece))), dtype='float64') / 10.0, DynPiece)\n",
    "#plt.plot(DynIdeal[:,0], DynIdeal[:,1])\n",
    "#plt.plot(DynHat[:,0], DynHat[:,1])\n",
    "plt.plot(DynPieces[choice])\n",
    "plt.plot(DynIdeal[choice][:,1])\n",
    "plt.plot(DynHat[choice][:,1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "PhraseDynamicsLSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
